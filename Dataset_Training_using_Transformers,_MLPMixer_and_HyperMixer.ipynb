{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYLRpvCW3m0h"
      },
      "source": [
        "# Dataset Training using **Transformer**, **MLPMixer** and **HyperMixer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkwFaE8LpZtX"
      },
      "source": [
        "### Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QvGt6CFqxzeg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Optional, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohHaXB2cpg2t"
      },
      "source": [
        "### Sentences and their Sentiment Labels lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTGlKk2uQH8v",
        "outputId": "5badbe63-3c24-494c-e8aa-6e502653b9da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(148, 148)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Sentences\n",
        "sentences = [\n",
        "    \"The sun is shining brightly today.\",\n",
        "    \"I can't stand the constant noise from construction outside.\",\n",
        "    \"This cake tastes delicious.\",\n",
        "    \"My internet connection keeps dropping, it's so frustrating.\",\n",
        "    \"The movie I watched last night was amazing.\",\n",
        "    \"I'm feeling indifferent about what to have for dinner tonight.\",\n",
        "    \"I got a promotion at work, I'm thrilled!\",\n",
        "    \"The customer service representative was rude and unhelpful.\",\n",
        "    \"Waking up to the sound of rain is so calming.\",\n",
        "    \"I'm feeling under the weather today.\",\n",
        "    \"The new restaurant in town has excellent food.\",\n",
        "    \"The traffic this morning was terrible.\",\n",
        "    \"Spending time with family always brings me joy.\",\n",
        "    \"My computer crashed and I lost all my work, I'm devastated.\",\n",
        "    \"I love the feeling of accomplishment after finishing a good book.\",\n",
        "    \"The constant barking of my neighbor's dog is irritating.\",\n",
        "    \"Traveling to new places is always exciting.\",\n",
        "    \"I'm feeling indifferent about attending the party tonight.\",\n",
        "    \"My favorite team won the championship, I'm ecstatic!\",\n",
        "    \"The food at the party was disappointing.\",\n",
        "    \"Watching the sunset by the beach is so peaceful.\",\n",
        "    \"I had a terrible headache all day.\",\n",
        "    \"Receiving unexpected gifts always puts a smile on my face.\",\n",
        "    \"The rainy weather ruined my plans for a picnic.\",\n",
        "    \"I love spending time with my pets, they bring me so much joy.\",\n",
        "    \"Dealing with customer complaints all day is exhausting.\",\n",
        "    \"The smell of fresh flowers is delightful.\",\n",
        "    \"My car broke down on the way to work, what a disaster.\",\n",
        "    \"Completing tasks on my to-do list gives me a sense of accomplishment.\",\n",
        "    \"I'm feeling indifferent about which movie to watch tonight.\",\n",
        "    \"I received a promotion at work, I'm over the moon!\",\n",
        "    \"The food at the new restaurant was mediocre.\",\n",
        "    \"Spending time in nature always rejuvenates me.\",\n",
        "    \"I had a horrible experience at the dentist today.\",\n",
        "    \"Watching my favorite TV show always cheers me up.\",\n",
        "    \"The long queues at the grocery store are frustrating.\",\n",
        "    \"Getting a good night's sleep makes me feel refreshed.\",\n",
        "    \"I'm feeling indifferent about what to wear to the party.\",\n",
        "    \"I passed my exam with flying colors, I'm elated!\",\n",
        "    \"The service at the hotel was terrible.\",\n",
        "    \"The smell of freshly baked cookies is heavenly.\",\n",
        "    \"I'm feeling down because I missed my flight.\",\n",
        "    \"Spending time with loved ones is priceless.\",\n",
        "    \"My phone screen cracked, I'm so upset.\",\n",
        "    \"Hearing my favorite song on the radio always lifts my spirits.\",\n",
        "    \"The constant honking of horns in traffic is annoying.\",\n",
        "    \"Enjoying a cup of hot chocolate on a cold day is comforting.\",\n",
        "    \"I'm feeling indifferent about where to go for vacation.\",\n",
        "    \"I received a promotion at work, I couldn't be happier!\",\n",
        "    \"The food at the restaurant was subpar.\",\n",
        "    \"Seeing a rainbow after the rain is magical.\",\n",
        "    \"I had a terrible day at work.\",\n",
        "    \"Receiving compliments from others always boosts my confidence.\",\n",
        "    \"The loud music from the neighbor's party kept me awake all night.\",\n",
        "    \"Reaching a personal goal brings a sense of fulfillment.\",\n",
        "    \"I'm feeling indifferent about what book to read next.\",\n",
        "    \"I won a prize in a contest, I'm thrilled!\",\n",
        "    \"The customer service hotline was unresponsive.\",\n",
        "    \"Watching a sunrise is a beautiful experience.\",\n",
        "    \"I'm feeling upset because I missed my train.\",\n",
        "    \"Achieving a personal best in a workout is empowering.\",\n",
        "    \"I'm feeling indifferent about what to do this weekend.\",\n",
        "    \"I received a compliment on my presentation, it made my day!\",\n",
        "    \"The constant beeping of car horns in traffic is annoying.\",\n",
        "    \"Visiting a botanical garden is a serene experience.\",\n",
        "    \"I'm feeling frustrated because my internet is so slow.\",\n",
        "    \"Enjoying a bubble bath after a long day is so relaxing.\",\n",
        "    \"I'm feeling indifferent about which restaurant to choose for dinner.\",\n",
        "    \"I won tickets to my favorite band's concert, I'm over the moon!\",\n",
        "    \"The food at the party was tasteless and cold.\",\n",
        "    \"Stargazing on a clear night is awe-inspiring.\",\n",
        "    \"I'm feeling down because I lost my wallet.\",\n",
        "    \"Receiving a handwritten letter from a friend brightened my day.\",\n",
        "    \"The loud music from the neighbor's party is keeping me awake.\",\n",
        "    \"Accomplishing a difficult task feels incredibly rewarding.\",\n",
        "    \"I'm feeling indifferent about what to do this evening.\",\n",
        "    \"I received praise from my boss for a job well done, I'm thrilled!\",\n",
        "    \"The service at the restaurant was slow and the food was cold.\",\n",
        "    \"The aroma of freshly brewed coffee is invigorating.\",\n",
        "    \"I'm feeling frustrated because I can't find my keys.\",\n",
        "    \"Taking a walk in the park on a sunny day is refreshing.\",\n",
        "    \"I'm disappointed because my favorite show got canceled.\",\n",
        "    \"Receiving a compliment from a stranger made my day.\",\n",
        "    \"The traffic jam made me late for my appointment.\",\n",
        "    \"I'm feeling indifferent about trying a new restaurant.\",\n",
        "    \"The food at the party was tasteless and uninspiring.\",\n",
        "    \"Listening to my favorite music always improves my mood.\",\n",
        "    \"I'm feeling down because I missed the train.\",\n",
        "    \"The beauty of nature never fails to amaze me.\",\n",
        "    \"I'm upset because my plans got canceled at the last minute.\",\n",
        "    \"Catching up with an old friend always brings joy.\",\n",
        "    \"The constant beeping of car horns in traffic is irritating.\",\n",
        "    \"Reading a good book transports me to another world.\",\n",
        "    \"I'm feeling frustrated because of the long wait in line.\",\n",
        "    \"The taste of homemade cookies is unparalleled.\",\n",
        "    \"I'm excited because I'm going on vacation next week.\",\n",
        "    \"Witnessing acts of kindness restores my faith in humanity.\",\n",
        "    \"I'm feeling indifferent about what to do this weekend.\",\n",
        "    \"The news of the unexpected promotion filled me with joy.\",\n",
        "    \"The food at the restaurant was disappointing and overpriced.\",\n",
        "    \"The flowers in the garden are blooming beautifully.\",\n",
        "    \"I'm frustrated with the slow internet speed.\",\n",
        "    \"Eating ice cream on a hot day is so refreshing.\",\n",
        "    \"The constant noise from the construction site is unbearable.\",\n",
        "    \"Winning the lottery would be a dream come true.\",\n",
        "    \"I'm feeling indifferent about what to watch on TV tonight.\",\n",
        "    \"Attending my best friend's wedding fills me with joy.\",\n",
        "    \"The rude behavior of the cashier ruined my shopping experience.\",\n",
        "    \"Listening to my favorite song always lifts my spirits.\",\n",
        "    \"The long wait at the doctor's office is frustrating.\",\n",
        "    \"Walking in the rain without an umbrella is not enjoyable.\",\n",
        "    \"Receiving a compliment from a stranger brightens my day.\",\n",
        "    \"I'm ecstatic about the upcoming vacation.\",\n",
        "    \"The taste of burnt food is unpleasant.\",\n",
        "    \"The breathtaking view from the mountaintop is awe-inspiring.\",\n",
        "    \"Dealing with a broken phone is inconvenient.\",\n",
        "    \"Playing with puppies brings me happiness.\",\n",
        "    \"The constant honking of horns in traffic is annoying.\",\n",
        "    \"Catching up with old friends is always fun.\",\n",
        "    \"The unexpected rain ruined our picnic plans.\",\n",
        "    \"Getting a promotion at work is exciting.\",\n",
        "    \"The smell of fresh bread baking is delightful.\",\n",
        "    \"I'm feeling down because I lost my wallet.\",\n",
        "    \"Watching a sunset on the beach is peaceful.\",\n",
        "    \"The loud music from the party next door is disturbing.\",\n",
        "    \"Reading a good book before bed helps me relax.\",\n",
        "    \"I'm frustrated with the lack of communication from my partner.\",\n",
        "    \"Seeing a shooting star is a rare and magical experience.\",\n",
        "    \"The broken elevator in the building is inconvenient.\",\n",
        "    \"Receiving a handwritten letter from a friend warms my heart.\",\n",
        "    \"I'm overjoyed to be spending time with my family.\",\n",
        "    \"The taste of bitter medicine is unpleasant.\",\n",
        "    \"The beautiful colors of autumn leaves are mesmerizing.\",\n",
        "    \"Dealing with rude customers is exhausting.\",\n",
        "    \"Finding money in an old jacket pocket is a pleasant surprise.\",\n",
        "    \"I'm feeling indifferent about going to the gym today.\",\n",
        "    \"The smell of fresh coffee in the morning is invigorating.\",\n",
        "    \"I'm disappointed because my favorite restaurant is closed.\",\n",
        "    \"Spending time in nature helps me relax and recharge.\",\n",
        "    \"The constant ringing of the phone is irritating.\",\n",
        "    \"Receiving a hug from a loved one is comforting.\",\n",
        "    \"I'm excited to try the new restaurant in town.\",\n",
        "    \"The taste of homemade cookies is unbeatable.\",\n",
        "    \"I'm upset because my flight got canceled.\",\n",
        "    \"Watching a comedy show always makes me laugh.\",\n",
        "    \"The never-ending emails in my inbox are overwhelming.\",\n",
        "    \"Receiving a thoughtful gift from a friend is heartwarming.\",\n",
        "    \"I'm indifferent about what to cook for dinner tonight.\"\n",
        "\n",
        "]\n",
        "\n",
        "# Sentiment Labels\n",
        "sentiment_labels = [\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Neutral\", \"Positive\", \"Negative\", \"Positive\", \"Negative\",\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Negative\", \"Positive\", \"Neutral\", \"Positive\", \"Negative\",\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Negative\", \"Positive\", \"Negative\", \"Positive\", \"Neutral\",\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Negative\", \"Positive\", \"Neutral\", \"Positive\", \"Negative\",\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Negative\", \"Positive\", \"Negative\", \"Positive\", \"Neutral\",\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Negative\", \"Positive\", \"Negative\", \"Positive\", \"Neutral\",\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Negative\", \"Positive\", \"Negative\", \"Positive\", \"Neutral\",\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Negative\", \"Positive\", \"Negative\",\"Positive\", \"Negative\",\n",
        "    \"Positive\", \"Negative\", \"Positive\",\"Negative\", \"Neutral\",\n",
        "    \"Negative\", \"Positive\", \"Negative\",\"Positive\", \"Negative\",\n",
        "    \"Positive\", \"Negative\", \"Positive\",\"Negative\", \"Positive\",\n",
        "    \"Positive\", \"Positive\", \"Neutral\",\"Positive\", \"Negative\",\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Neutral\", \"Positive\", \"Negative\", \"Positive\", \"Negative\",\n",
        "    \"Negative\", \"Positive\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Negative\", \"Positive\", \"Negative\", \"Positive\", \"Negative\",\n",
        "    \"Positive\", \"Positive\", \"Negative\", \"Positive\", \"Negative\",\n",
        "    \"Negative\", \"Positive\", \"Positive\", \"Negative\", \"Positive\",\n",
        "    \"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Negative\",\n",
        "    \"Positive\", \"Positive\", \"Negative\", \"Positive\", \"Positive\",\n",
        "    \"Negative\", \"Positive\", \"Negative\", \"Positive\", \"Negative\",\n",
        "    \"Positive\", \"Positive\", \"Negative\",\n",
        "]\n",
        "\n",
        "len(sentences), len(sentiment_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOv6-MyM_D59",
        "outputId": "2b8e38c1-0626-4480-814d-42fc27b6da45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76, 62, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Count occurrences of each label\n",
        "positive_count = sentiment_labels.count(\"Positive\")\n",
        "negative_count = sentiment_labels.count(\"Negative\")\n",
        "neutral_count = sentiment_labels.count(\"Neutral\")\n",
        "\n",
        "# Print the counts\n",
        "positive_count, negative_count, neutral_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVCIcwWApsFo"
      },
      "source": [
        "\n",
        "### 1.  Creating a dataset of 148 sentences with sentiment labels as either **positive, negative** or **neutral**.\n",
        "### 2.    Then creating a training and test set respectively\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sGd2KrRwXLr",
        "outputId": "6464d5a7-72f7-4dbe-8aaa-b9adb9bb8576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Size:(118, 2)\n",
            "Test Set Size:(30, 2)\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame\n",
        "df = pd.DataFrame({'Sentence': sentences, 'Sentiment': sentiment_labels})\n",
        "\n",
        "# Shuffle the Dataset\n",
        "random.shuffle(df.values)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print training set\n",
        "print(f\"Training Set Size:{train_df.shape}\")\n",
        "\n",
        "# Print test set\n",
        "print(f\"Test Set Size:{test_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Sakr61dqya6E"
      },
      "outputs": [],
      "source": [
        "MLP_mixer_accuracies=[]\n",
        "MLP_mixer_runtimes = []\n",
        "\n",
        "Transformer_accuracies=[]\n",
        "Transformer_runtimes = []\n",
        "\n",
        "HyperMixer_accuracies=[]\n",
        "HyperMixer_runtimes = []\n",
        "\n",
        "n=50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50Fxs-GqqJSj"
      },
      "source": [
        "### MLP Mixer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3Ss8pijQJWr",
        "outputId": "c4ddf50c-21b2-45c3-8fc3-46325aaa19c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.1268, Accuracy: 0.0593\n",
            "Epoch [2/5], Loss: 1.1126, Accuracy: 0.2797\n",
            "Epoch [3/5], Loss: 1.0992, Accuracy: 0.3898\n",
            "Epoch [4/5], Loss: 1.0860, Accuracy: 0.3814\n",
            "Epoch [5/5], Loss: 1.0728, Accuracy: 0.4237\n",
            "1 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1319, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1149, Accuracy: 0.1186\n",
            "Epoch [3/5], Loss: 1.0989, Accuracy: 0.3475\n",
            "Epoch [4/5], Loss: 1.0834, Accuracy: 0.4322\n",
            "Epoch [5/5], Loss: 1.0682, Accuracy: 0.6441\n",
            "2 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0742, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 1.0597, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0461, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0329, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0198, Accuracy: 0.5678\n",
            "3 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1030, Accuracy: 0.5254\n",
            "Epoch [2/5], Loss: 1.0871, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0721, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0574, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0427, Accuracy: 0.5678\n",
            "4 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0774, Accuracy: 0.3814\n",
            "Epoch [2/5], Loss: 1.0604, Accuracy: 0.3814\n",
            "Epoch [3/5], Loss: 1.0437, Accuracy: 0.3814\n",
            "Epoch [4/5], Loss: 1.0268, Accuracy: 0.3983\n",
            "Epoch [5/5], Loss: 1.0096, Accuracy: 0.5000\n",
            "5 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1508, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1358, Accuracy: 0.0508\n",
            "Epoch [3/5], Loss: 1.1214, Accuracy: 0.1780\n",
            "Epoch [4/5], Loss: 1.1072, Accuracy: 0.3051\n",
            "Epoch [5/5], Loss: 1.0933, Accuracy: 0.3983\n",
            "6 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1185, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1033, Accuracy: 0.1356\n",
            "Epoch [3/5], Loss: 1.0885, Accuracy: 0.5424\n",
            "Epoch [4/5], Loss: 1.0736, Accuracy: 0.5932\n",
            "Epoch [5/5], Loss: 1.0587, Accuracy: 0.5847\n",
            "7 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0861, Accuracy: 0.5169\n",
            "Epoch [2/5], Loss: 1.0722, Accuracy: 0.6186\n",
            "Epoch [3/5], Loss: 1.0588, Accuracy: 0.6441\n",
            "Epoch [4/5], Loss: 1.0454, Accuracy: 0.6525\n",
            "Epoch [5/5], Loss: 1.0319, Accuracy: 0.6780\n",
            "8 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1015, Accuracy: 0.2458\n",
            "Epoch [2/5], Loss: 1.0876, Accuracy: 0.6017\n",
            "Epoch [3/5], Loss: 1.0745, Accuracy: 0.6356\n",
            "Epoch [4/5], Loss: 1.0617, Accuracy: 0.6356\n",
            "Epoch [5/5], Loss: 1.0489, Accuracy: 0.6356\n",
            "9 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0743, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 1.0593, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0449, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0310, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0171, Accuracy: 0.5678\n",
            "10 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1097, Accuracy: 0.1017\n",
            "Epoch [2/5], Loss: 1.0929, Accuracy: 0.3898\n",
            "Epoch [3/5], Loss: 1.0768, Accuracy: 0.5847\n",
            "Epoch [4/5], Loss: 1.0610, Accuracy: 0.6356\n",
            "Epoch [5/5], Loss: 1.0451, Accuracy: 0.6525\n",
            "11 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0952, Accuracy: 0.5169\n",
            "Epoch [2/5], Loss: 1.0822, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0693, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0563, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0429, Accuracy: 0.5678\n",
            "12 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1321, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1135, Accuracy: 0.0508\n",
            "Epoch [3/5], Loss: 1.0957, Accuracy: 0.2881\n",
            "Epoch [4/5], Loss: 1.0783, Accuracy: 0.6186\n",
            "Epoch [5/5], Loss: 1.0612, Accuracy: 0.5847\n",
            "13 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0743, Accuracy: 0.3983\n",
            "Epoch [2/5], Loss: 1.0605, Accuracy: 0.5085\n",
            "Epoch [3/5], Loss: 1.0476, Accuracy: 0.7288\n",
            "Epoch [4/5], Loss: 1.0347, Accuracy: 0.8898\n",
            "Epoch [5/5], Loss: 1.0216, Accuracy: 0.9237\n",
            "14 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0976, Accuracy: 0.4746\n",
            "Epoch [2/5], Loss: 1.0822, Accuracy: 0.6186\n",
            "Epoch [3/5], Loss: 1.0673, Accuracy: 0.7288\n",
            "Epoch [4/5], Loss: 1.0523, Accuracy: 0.8305\n",
            "Epoch [5/5], Loss: 1.0372, Accuracy: 0.8983\n",
            "15 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1353, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1202, Accuracy: 0.0508\n",
            "Epoch [3/5], Loss: 1.1057, Accuracy: 0.0593\n",
            "Epoch [4/5], Loss: 1.0917, Accuracy: 0.3898\n",
            "Epoch [5/5], Loss: 1.0777, Accuracy: 0.6186\n",
            "16 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1427, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1284, Accuracy: 0.0508\n",
            "Epoch [3/5], Loss: 1.1152, Accuracy: 0.1017\n",
            "Epoch [4/5], Loss: 1.1024, Accuracy: 0.2797\n",
            "Epoch [5/5], Loss: 1.0897, Accuracy: 0.4915\n",
            "17 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0736, Accuracy: 0.4068\n",
            "Epoch [2/5], Loss: 1.0577, Accuracy: 0.4746\n",
            "Epoch [3/5], Loss: 1.0424, Accuracy: 0.6949\n",
            "Epoch [4/5], Loss: 1.0273, Accuracy: 0.9068\n",
            "Epoch [5/5], Loss: 1.0119, Accuracy: 0.9322\n",
            "18 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1039, Accuracy: 0.3559\n",
            "Epoch [2/5], Loss: 1.0892, Accuracy: 0.3983\n",
            "Epoch [3/5], Loss: 1.0751, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0613, Accuracy: 0.6356\n",
            "Epoch [5/5], Loss: 1.0476, Accuracy: 0.8220\n",
            "19 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0782, Accuracy: 0.4831\n",
            "Epoch [2/5], Loss: 1.0635, Accuracy: 0.6441\n",
            "Epoch [3/5], Loss: 1.0494, Accuracy: 0.7712\n",
            "Epoch [4/5], Loss: 1.0355, Accuracy: 0.7881\n",
            "Epoch [5/5], Loss: 1.0214, Accuracy: 0.8136\n",
            "20 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0680, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 1.0544, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0410, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0273, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0130, Accuracy: 0.5678\n",
            "21 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1247, Accuracy: 0.2712\n",
            "Epoch [2/5], Loss: 1.1101, Accuracy: 0.3814\n",
            "Epoch [3/5], Loss: 1.0958, Accuracy: 0.3814\n",
            "Epoch [4/5], Loss: 1.0814, Accuracy: 0.3814\n",
            "Epoch [5/5], Loss: 1.0666, Accuracy: 0.3814\n",
            "22 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0839, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 1.0678, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0524, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0376, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0228, Accuracy: 0.5678\n",
            "23 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1050, Accuracy: 0.0763\n",
            "Epoch [2/5], Loss: 1.0898, Accuracy: 0.5085\n",
            "Epoch [3/5], Loss: 1.0750, Accuracy: 0.7034\n",
            "Epoch [4/5], Loss: 1.0600, Accuracy: 0.7627\n",
            "Epoch [5/5], Loss: 1.0447, Accuracy: 0.7797\n",
            "24 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1302, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1135, Accuracy: 0.0508\n",
            "Epoch [3/5], Loss: 1.0977, Accuracy: 0.2712\n",
            "Epoch [4/5], Loss: 1.0821, Accuracy: 0.8390\n",
            "Epoch [5/5], Loss: 1.0667, Accuracy: 0.9068\n",
            "25 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0872, Accuracy: 0.5847\n",
            "Epoch [2/5], Loss: 1.0721, Accuracy: 0.6441\n",
            "Epoch [3/5], Loss: 1.0572, Accuracy: 0.6695\n",
            "Epoch [4/5], Loss: 1.0422, Accuracy: 0.6271\n",
            "Epoch [5/5], Loss: 1.0266, Accuracy: 0.6017\n",
            "26 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0776, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 1.0646, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0523, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0403, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0286, Accuracy: 0.5678\n",
            "27 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1232, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1056, Accuracy: 0.1949\n",
            "Epoch [3/5], Loss: 1.0893, Accuracy: 0.5000\n",
            "Epoch [4/5], Loss: 1.0735, Accuracy: 0.7881\n",
            "Epoch [5/5], Loss: 1.0580, Accuracy: 0.8644\n",
            "28 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1002, Accuracy: 0.4407\n",
            "Epoch [2/5], Loss: 1.0823, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0651, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0484, Accuracy: 0.5932\n",
            "Epoch [5/5], Loss: 1.0320, Accuracy: 0.5932\n",
            "29 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0663, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 1.0523, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0388, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0255, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0124, Accuracy: 0.5678\n",
            "30 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0935, Accuracy: 0.5932\n",
            "Epoch [2/5], Loss: 1.0766, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0606, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0450, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0296, Accuracy: 0.5678\n",
            "31 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1100, Accuracy: 0.1525\n",
            "Epoch [2/5], Loss: 1.0960, Accuracy: 0.3814\n",
            "Epoch [3/5], Loss: 1.0823, Accuracy: 0.5169\n",
            "Epoch [4/5], Loss: 1.0687, Accuracy: 0.7203\n",
            "Epoch [5/5], Loss: 1.0547, Accuracy: 0.8305\n",
            "32 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1212, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1048, Accuracy: 0.1271\n",
            "Epoch [3/5], Loss: 1.0891, Accuracy: 0.6949\n",
            "Epoch [4/5], Loss: 1.0742, Accuracy: 0.8644\n",
            "Epoch [5/5], Loss: 1.0595, Accuracy: 0.9153\n",
            "33 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1202, Accuracy: 0.1271\n",
            "Epoch [2/5], Loss: 1.1056, Accuracy: 0.3051\n",
            "Epoch [3/5], Loss: 1.0917, Accuracy: 0.4153\n",
            "Epoch [4/5], Loss: 1.0779, Accuracy: 0.5847\n",
            "Epoch [5/5], Loss: 1.0638, Accuracy: 0.7712\n",
            "34 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1263, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1096, Accuracy: 0.0508\n",
            "Epoch [3/5], Loss: 1.0939, Accuracy: 0.2881\n",
            "Epoch [4/5], Loss: 1.0787, Accuracy: 0.7966\n",
            "Epoch [5/5], Loss: 1.0633, Accuracy: 0.7797\n",
            "35 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0991, Accuracy: 0.4237\n",
            "Epoch [2/5], Loss: 1.0834, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0685, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0541, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0399, Accuracy: 0.5678\n",
            "36 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0562, Accuracy: 0.5932\n",
            "Epoch [2/5], Loss: 1.0410, Accuracy: 0.5932\n",
            "Epoch [3/5], Loss: 1.0261, Accuracy: 0.5932\n",
            "Epoch [4/5], Loss: 1.0111, Accuracy: 0.6102\n",
            "Epoch [5/5], Loss: 0.9956, Accuracy: 0.6102\n",
            "37 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0899, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 1.0756, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0619, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0483, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0347, Accuracy: 0.5678\n",
            "38 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0953, Accuracy: 0.3898\n",
            "Epoch [2/5], Loss: 1.0808, Accuracy: 0.6102\n",
            "Epoch [3/5], Loss: 1.0670, Accuracy: 0.8051\n",
            "Epoch [4/5], Loss: 1.0533, Accuracy: 0.8729\n",
            "Epoch [5/5], Loss: 1.0397, Accuracy: 0.8983\n",
            "39 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0767, Accuracy: 0.3814\n",
            "Epoch [2/5], Loss: 1.0596, Accuracy: 0.4407\n",
            "Epoch [3/5], Loss: 1.0431, Accuracy: 0.6102\n",
            "Epoch [4/5], Loss: 1.0268, Accuracy: 0.7712\n",
            "Epoch [5/5], Loss: 1.0105, Accuracy: 0.8644\n",
            "40 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0691, Accuracy: 0.3814\n",
            "Epoch [2/5], Loss: 1.0534, Accuracy: 0.3814\n",
            "Epoch [3/5], Loss: 1.0378, Accuracy: 0.3814\n",
            "Epoch [4/5], Loss: 1.0220, Accuracy: 0.4153\n",
            "Epoch [5/5], Loss: 1.0056, Accuracy: 0.5254\n",
            "41 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1070, Accuracy: 0.3814\n",
            "Epoch [2/5], Loss: 1.0911, Accuracy: 0.3814\n",
            "Epoch [3/5], Loss: 1.0760, Accuracy: 0.3814\n",
            "Epoch [4/5], Loss: 1.0614, Accuracy: 0.3814\n",
            "Epoch [5/5], Loss: 1.0471, Accuracy: 0.3814\n",
            "42 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1121, Accuracy: 0.1271\n",
            "Epoch [2/5], Loss: 1.0948, Accuracy: 0.4322\n",
            "Epoch [3/5], Loss: 1.0784, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0625, Accuracy: 0.6949\n",
            "Epoch [5/5], Loss: 1.0467, Accuracy: 0.8644\n",
            "43 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1208, Accuracy: 0.0508\n",
            "Epoch [2/5], Loss: 1.1038, Accuracy: 0.1102\n",
            "Epoch [3/5], Loss: 1.0872, Accuracy: 0.6102\n",
            "Epoch [4/5], Loss: 1.0706, Accuracy: 0.8136\n",
            "Epoch [5/5], Loss: 1.0537, Accuracy: 0.7966\n",
            "44 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0773, Accuracy: 0.4661\n",
            "Epoch [2/5], Loss: 1.0622, Accuracy: 0.7119\n",
            "Epoch [3/5], Loss: 1.0478, Accuracy: 0.8559\n",
            "Epoch [4/5], Loss: 1.0336, Accuracy: 0.8729\n",
            "Epoch [5/5], Loss: 1.0193, Accuracy: 0.8898\n",
            "45 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1133, Accuracy: 0.0678\n",
            "Epoch [2/5], Loss: 1.0969, Accuracy: 0.4492\n",
            "Epoch [3/5], Loss: 1.0811, Accuracy: 0.5339\n",
            "Epoch [4/5], Loss: 1.0657, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0503, Accuracy: 0.5678\n",
            "46 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1086, Accuracy: 0.3814\n",
            "Epoch [2/5], Loss: 1.0929, Accuracy: 0.3814\n",
            "Epoch [3/5], Loss: 1.0778, Accuracy: 0.3814\n",
            "Epoch [4/5], Loss: 1.0630, Accuracy: 0.3983\n",
            "Epoch [5/5], Loss: 1.0480, Accuracy: 0.4576\n",
            "47 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0869, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 1.0720, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 1.0576, Accuracy: 0.6017\n",
            "Epoch [4/5], Loss: 1.0436, Accuracy: 0.6017\n",
            "Epoch [5/5], Loss: 1.0297, Accuracy: 0.6186\n",
            "48 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0929, Accuracy: 0.4153\n",
            "Epoch [2/5], Loss: 1.0766, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0610, Accuracy: 0.7881\n",
            "Epoch [4/5], Loss: 1.0459, Accuracy: 0.9153\n",
            "Epoch [5/5], Loss: 1.0307, Accuracy: 0.9153\n",
            "49 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0726, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 1.0579, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 1.0437, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 1.0297, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 1.0155, Accuracy: 0.5678\n",
            "50 Run Complete!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define MLP-Mixer model\n",
        "class MLP_Mixer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super(MLP_Mixer, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['Label'] = label_encoder.fit_transform(train_df['Sentiment'])\n",
        "\n",
        "# Convert sentences to numerical representation\n",
        "vocab = set(\" \".join(train_df['Sentence']).split())\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "def sentence_to_one_hot(sentence):\n",
        "    one_hot = [0] * len(vocab)\n",
        "    for word in sentence.split():\n",
        "        one_hot[word_to_index[word]] = 1\n",
        "    return one_hot\n",
        "\n",
        "train_data = torch.tensor([sentence_to_one_hot(sentence) for sentence in train_df['Sentence']], dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_df['Label'].values, dtype=torch.long)\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = len(vocab)  # Vocabulary size\n",
        "hidden_dim = 128\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "\n",
        "for i  in range(n):\n",
        "    # Instantiate MLP-Mixer model\n",
        "    model = MLP_Mixer(input_dim, hidden_dim, num_classes)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    accuracies_MLPMixer=[]\n",
        "    start_time = time.time()  # Start time for each run\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 5\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(train_data)\n",
        "        loss = criterion(outputs, train_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = accuracy_score(train_labels.numpy(), predicted.numpy())\n",
        "        accuracies_MLPMixer.append(accuracy)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    end_time = time.time()  # End time for each run\n",
        "    runtime = end_time - start_time\n",
        "    MLP_mixer_accuracies.append(np.mean(accuracies_MLPMixer))\n",
        "    MLP_mixer_runtimes.append(runtime)\n",
        "    print(f\"{i+1} Run Complete!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGmhhJrJqL4d"
      },
      "source": [
        "### Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdDGXjxLcfjZ",
        "outputId": "c7b62dd5-dc97-4bdd-e2c5-dfdc1265cbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.0659, Accuracy: 0.4915\n",
            "Epoch [2/5], Loss: 0.6736, Accuracy: 0.7034\n",
            "Epoch [3/5], Loss: 0.3680, Accuracy: 0.8814\n",
            "Epoch [4/5], Loss: 0.2252, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.1603, Accuracy: 0.9492\n",
            "1 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9711, Accuracy: 0.5000\n",
            "Epoch [2/5], Loss: 0.9399, Accuracy: 0.5169\n",
            "Epoch [3/5], Loss: 0.5739, Accuracy: 0.8220\n",
            "Epoch [4/5], Loss: 0.3655, Accuracy: 0.9068\n",
            "Epoch [5/5], Loss: 0.2060, Accuracy: 0.9322\n",
            "2 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0301, Accuracy: 0.4661\n",
            "Epoch [2/5], Loss: 0.7284, Accuracy: 0.6356\n",
            "Epoch [3/5], Loss: 0.3530, Accuracy: 0.8898\n",
            "Epoch [4/5], Loss: 0.2499, Accuracy: 0.9153\n",
            "Epoch [5/5], Loss: 0.2459, Accuracy: 0.9237\n",
            "3 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9966, Accuracy: 0.4831\n",
            "Epoch [2/5], Loss: 0.5112, Accuracy: 0.7966\n",
            "Epoch [3/5], Loss: 0.2602, Accuracy: 0.9068\n",
            "Epoch [4/5], Loss: 0.1367, Accuracy: 0.9576\n",
            "Epoch [5/5], Loss: 0.1877, Accuracy: 0.9322\n",
            "4 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0470, Accuracy: 0.5424\n",
            "Epoch [2/5], Loss: 0.8558, Accuracy: 0.6102\n",
            "Epoch [3/5], Loss: 0.5943, Accuracy: 0.8220\n",
            "Epoch [4/5], Loss: 0.3536, Accuracy: 0.9153\n",
            "Epoch [5/5], Loss: 0.2725, Accuracy: 0.9153\n",
            "5 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9428, Accuracy: 0.5508\n",
            "Epoch [2/5], Loss: 0.5424, Accuracy: 0.7966\n",
            "Epoch [3/5], Loss: 0.1831, Accuracy: 0.9407\n",
            "Epoch [4/5], Loss: 0.1613, Accuracy: 0.9407\n",
            "Epoch [5/5], Loss: 0.1914, Accuracy: 0.9661\n",
            "6 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0527, Accuracy: 0.4746\n",
            "Epoch [2/5], Loss: 0.7619, Accuracy: 0.6695\n",
            "Epoch [3/5], Loss: 0.4748, Accuracy: 0.8390\n",
            "Epoch [4/5], Loss: 0.3661, Accuracy: 0.8898\n",
            "Epoch [5/5], Loss: 0.2879, Accuracy: 0.8983\n",
            "7 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9992, Accuracy: 0.4831\n",
            "Epoch [2/5], Loss: 0.8793, Accuracy: 0.5254\n",
            "Epoch [3/5], Loss: 0.5985, Accuracy: 0.7542\n",
            "Epoch [4/5], Loss: 0.2965, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.2348, Accuracy: 0.9237\n",
            "8 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0282, Accuracy: 0.5000\n",
            "Epoch [2/5], Loss: 0.4901, Accuracy: 0.8729\n",
            "Epoch [3/5], Loss: 0.2626, Accuracy: 0.9237\n",
            "Epoch [4/5], Loss: 0.2207, Accuracy: 0.9407\n",
            "Epoch [5/5], Loss: 0.1934, Accuracy: 0.9322\n",
            "9 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9811, Accuracy: 0.5169\n",
            "Epoch [2/5], Loss: 0.6082, Accuracy: 0.7797\n",
            "Epoch [3/5], Loss: 0.3737, Accuracy: 0.8729\n",
            "Epoch [4/5], Loss: 0.2413, Accuracy: 0.9237\n",
            "Epoch [5/5], Loss: 0.2282, Accuracy: 0.9237\n",
            "10 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0334, Accuracy: 0.5254\n",
            "Epoch [2/5], Loss: 0.5796, Accuracy: 0.8051\n",
            "Epoch [3/5], Loss: 0.4591, Accuracy: 0.8220\n",
            "Epoch [4/5], Loss: 0.1873, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.1458, Accuracy: 0.9407\n",
            "11 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0273, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 0.4169, Accuracy: 0.8220\n",
            "Epoch [3/5], Loss: 0.3032, Accuracy: 0.8983\n",
            "Epoch [4/5], Loss: 0.0876, Accuracy: 0.9661\n",
            "Epoch [5/5], Loss: 0.0405, Accuracy: 0.9915\n",
            "12 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9523, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 0.4550, Accuracy: 0.8220\n",
            "Epoch [3/5], Loss: 0.2687, Accuracy: 0.9237\n",
            "Epoch [4/5], Loss: 0.2405, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.2505, Accuracy: 0.9322\n",
            "13 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0212, Accuracy: 0.4915\n",
            "Epoch [2/5], Loss: 0.8762, Accuracy: 0.4831\n",
            "Epoch [3/5], Loss: 0.5496, Accuracy: 0.8051\n",
            "Epoch [4/5], Loss: 0.2938, Accuracy: 0.9237\n",
            "Epoch [5/5], Loss: 0.2509, Accuracy: 0.9237\n",
            "14 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0737, Accuracy: 0.4831\n",
            "Epoch [2/5], Loss: 0.7495, Accuracy: 0.7034\n",
            "Epoch [3/5], Loss: 0.3544, Accuracy: 0.9153\n",
            "Epoch [4/5], Loss: 0.2402, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.1918, Accuracy: 0.9407\n",
            "15 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0097, Accuracy: 0.5763\n",
            "Epoch [2/5], Loss: 0.8890, Accuracy: 0.5085\n",
            "Epoch [3/5], Loss: 0.8558, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 0.5912, Accuracy: 0.7712\n",
            "Epoch [5/5], Loss: 0.4374, Accuracy: 0.8475\n",
            "16 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0911, Accuracy: 0.5424\n",
            "Epoch [2/5], Loss: 0.8623, Accuracy: 0.5508\n",
            "Epoch [3/5], Loss: 0.8868, Accuracy: 0.4576\n",
            "Epoch [4/5], Loss: 0.8679, Accuracy: 0.5763\n",
            "Epoch [5/5], Loss: 0.6671, Accuracy: 0.8305\n",
            "17 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0333, Accuracy: 0.5254\n",
            "Epoch [2/5], Loss: 0.7002, Accuracy: 0.7119\n",
            "Epoch [3/5], Loss: 0.2885, Accuracy: 0.9153\n",
            "Epoch [4/5], Loss: 0.2037, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.1497, Accuracy: 0.9322\n",
            "18 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0268, Accuracy: 0.5254\n",
            "Epoch [2/5], Loss: 0.9154, Accuracy: 0.5085\n",
            "Epoch [3/5], Loss: 0.5504, Accuracy: 0.8305\n",
            "Epoch [4/5], Loss: 0.4314, Accuracy: 0.8559\n",
            "Epoch [5/5], Loss: 0.3272, Accuracy: 0.8729\n",
            "19 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0564, Accuracy: 0.5085\n",
            "Epoch [2/5], Loss: 0.7808, Accuracy: 0.6186\n",
            "Epoch [3/5], Loss: 0.4329, Accuracy: 0.8814\n",
            "Epoch [4/5], Loss: 0.2622, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.1823, Accuracy: 0.9407\n",
            "20 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0544, Accuracy: 0.5000\n",
            "Epoch [2/5], Loss: 0.5427, Accuracy: 0.8305\n",
            "Epoch [3/5], Loss: 0.3549, Accuracy: 0.9068\n",
            "Epoch [4/5], Loss: 0.1708, Accuracy: 0.9492\n",
            "Epoch [5/5], Loss: 0.1759, Accuracy: 0.9407\n",
            "21 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0442, Accuracy: 0.5508\n",
            "Epoch [2/5], Loss: 0.9083, Accuracy: 0.5254\n",
            "Epoch [3/5], Loss: 0.6411, Accuracy: 0.7966\n",
            "Epoch [4/5], Loss: 0.3126, Accuracy: 0.8898\n",
            "Epoch [5/5], Loss: 0.2026, Accuracy: 0.9492\n",
            "22 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9313, Accuracy: 0.6525\n",
            "Epoch [2/5], Loss: 0.4270, Accuracy: 0.8475\n",
            "Epoch [3/5], Loss: 0.2355, Accuracy: 0.9322\n",
            "Epoch [4/5], Loss: 0.1813, Accuracy: 0.9407\n",
            "Epoch [5/5], Loss: 0.1728, Accuracy: 0.9492\n",
            "23 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.8577, Accuracy: 0.6102\n",
            "Epoch [2/5], Loss: 0.4336, Accuracy: 0.8305\n",
            "Epoch [3/5], Loss: 0.2074, Accuracy: 0.9237\n",
            "Epoch [4/5], Loss: 0.1944, Accuracy: 0.9153\n",
            "Epoch [5/5], Loss: 0.0755, Accuracy: 0.9661\n",
            "24 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1349, Accuracy: 0.4661\n",
            "Epoch [2/5], Loss: 0.8616, Accuracy: 0.6186\n",
            "Epoch [3/5], Loss: 0.5776, Accuracy: 0.7881\n",
            "Epoch [4/5], Loss: 0.4340, Accuracy: 0.8644\n",
            "Epoch [5/5], Loss: 0.6733, Accuracy: 0.7966\n",
            "25 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.8805, Accuracy: 0.6864\n",
            "Epoch [2/5], Loss: 0.5082, Accuracy: 0.8559\n",
            "Epoch [3/5], Loss: 0.2190, Accuracy: 0.9407\n",
            "Epoch [4/5], Loss: 0.2024, Accuracy: 0.9153\n",
            "Epoch [5/5], Loss: 0.1285, Accuracy: 0.9576\n",
            "26 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0039, Accuracy: 0.5169\n",
            "Epoch [2/5], Loss: 0.6839, Accuracy: 0.7458\n",
            "Epoch [3/5], Loss: 0.4021, Accuracy: 0.8898\n",
            "Epoch [4/5], Loss: 0.3034, Accuracy: 0.9237\n",
            "Epoch [5/5], Loss: 0.2466, Accuracy: 0.9237\n",
            "27 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0009, Accuracy: 0.5254\n",
            "Epoch [2/5], Loss: 0.5515, Accuracy: 0.8051\n",
            "Epoch [3/5], Loss: 0.2846, Accuracy: 0.9237\n",
            "Epoch [4/5], Loss: 0.2029, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.1910, Accuracy: 0.9322\n",
            "28 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1728, Accuracy: 0.4492\n",
            "Epoch [2/5], Loss: 0.7973, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 0.4914, Accuracy: 0.8390\n",
            "Epoch [4/5], Loss: 0.2439, Accuracy: 0.9237\n",
            "Epoch [5/5], Loss: 0.2376, Accuracy: 0.9407\n",
            "29 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1220, Accuracy: 0.4322\n",
            "Epoch [2/5], Loss: 0.8473, Accuracy: 0.6017\n",
            "Epoch [3/5], Loss: 0.5572, Accuracy: 0.7458\n",
            "Epoch [4/5], Loss: 0.2909, Accuracy: 0.8983\n",
            "Epoch [5/5], Loss: 0.1760, Accuracy: 0.9407\n",
            "30 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0154, Accuracy: 0.5169\n",
            "Epoch [2/5], Loss: 0.5813, Accuracy: 0.7542\n",
            "Epoch [3/5], Loss: 0.2693, Accuracy: 0.9068\n",
            "Epoch [4/5], Loss: 0.1945, Accuracy: 0.9407\n",
            "Epoch [5/5], Loss: 0.1594, Accuracy: 0.9492\n",
            "31 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1237, Accuracy: 0.4831\n",
            "Epoch [2/5], Loss: 0.7203, Accuracy: 0.6102\n",
            "Epoch [3/5], Loss: 0.4845, Accuracy: 0.8390\n",
            "Epoch [4/5], Loss: 0.2889, Accuracy: 0.9153\n",
            "Epoch [5/5], Loss: 0.2513, Accuracy: 0.9153\n",
            "32 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.2061, Accuracy: 0.4322\n",
            "Epoch [2/5], Loss: 0.8761, Accuracy: 0.5508\n",
            "Epoch [3/5], Loss: 0.8929, Accuracy: 0.5000\n",
            "Epoch [4/5], Loss: 0.7092, Accuracy: 0.6610\n",
            "Epoch [5/5], Loss: 0.3688, Accuracy: 0.8983\n",
            "33 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1965, Accuracy: 0.4661\n",
            "Epoch [2/5], Loss: 0.8850, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 0.8877, Accuracy: 0.4831\n",
            "Epoch [4/5], Loss: 0.7056, Accuracy: 0.6949\n",
            "Epoch [5/5], Loss: 0.2756, Accuracy: 0.9153\n",
            "34 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0433, Accuracy: 0.5085\n",
            "Epoch [2/5], Loss: 0.6174, Accuracy: 0.7458\n",
            "Epoch [3/5], Loss: 0.4971, Accuracy: 0.8305\n",
            "Epoch [4/5], Loss: 0.3151, Accuracy: 0.9068\n",
            "Epoch [5/5], Loss: 0.3236, Accuracy: 0.8898\n",
            "35 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9994, Accuracy: 0.5169\n",
            "Epoch [2/5], Loss: 0.7131, Accuracy: 0.6017\n",
            "Epoch [3/5], Loss: 0.3626, Accuracy: 0.8898\n",
            "Epoch [4/5], Loss: 0.1817, Accuracy: 0.9407\n",
            "Epoch [5/5], Loss: 0.2169, Accuracy: 0.9407\n",
            "36 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1512, Accuracy: 0.4661\n",
            "Epoch [2/5], Loss: 0.9048, Accuracy: 0.5424\n",
            "Epoch [3/5], Loss: 0.8509, Accuracy: 0.5763\n",
            "Epoch [4/5], Loss: 0.4519, Accuracy: 0.8644\n",
            "Epoch [5/5], Loss: 0.3162, Accuracy: 0.8983\n",
            "37 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0717, Accuracy: 0.5085\n",
            "Epoch [2/5], Loss: 0.6119, Accuracy: 0.7712\n",
            "Epoch [3/5], Loss: 0.3014, Accuracy: 0.9153\n",
            "Epoch [4/5], Loss: 0.2390, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.1337, Accuracy: 0.9492\n",
            "38 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0021, Accuracy: 0.5424\n",
            "Epoch [2/5], Loss: 0.7984, Accuracy: 0.6102\n",
            "Epoch [3/5], Loss: 0.3833, Accuracy: 0.8559\n",
            "Epoch [4/5], Loss: 0.2278, Accuracy: 0.9407\n",
            "Epoch [5/5], Loss: 0.1992, Accuracy: 0.9407\n",
            "39 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9899, Accuracy: 0.5085\n",
            "Epoch [2/5], Loss: 0.5985, Accuracy: 0.7288\n",
            "Epoch [3/5], Loss: 0.2685, Accuracy: 0.9068\n",
            "Epoch [4/5], Loss: 0.1790, Accuracy: 0.9492\n",
            "Epoch [5/5], Loss: 0.1954, Accuracy: 0.9237\n",
            "40 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0657, Accuracy: 0.5169\n",
            "Epoch [2/5], Loss: 0.7742, Accuracy: 0.6525\n",
            "Epoch [3/5], Loss: 0.4049, Accuracy: 0.8814\n",
            "Epoch [4/5], Loss: 0.2317, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.0526, Accuracy: 0.9831\n",
            "41 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0925, Accuracy: 0.5339\n",
            "Epoch [2/5], Loss: 0.8983, Accuracy: 0.4746\n",
            "Epoch [3/5], Loss: 0.6967, Accuracy: 0.7542\n",
            "Epoch [4/5], Loss: 0.5032, Accuracy: 0.8475\n",
            "Epoch [5/5], Loss: 0.4355, Accuracy: 0.8475\n",
            "42 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0285, Accuracy: 0.5508\n",
            "Epoch [2/5], Loss: 0.7631, Accuracy: 0.6780\n",
            "Epoch [3/5], Loss: 0.4220, Accuracy: 0.8729\n",
            "Epoch [4/5], Loss: 0.2204, Accuracy: 0.9237\n",
            "Epoch [5/5], Loss: 0.2289, Accuracy: 0.9322\n",
            "43 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1227, Accuracy: 0.4576\n",
            "Epoch [2/5], Loss: 0.8907, Accuracy: 0.5254\n",
            "Epoch [3/5], Loss: 0.6526, Accuracy: 0.7119\n",
            "Epoch [4/5], Loss: 0.3645, Accuracy: 0.8814\n",
            "Epoch [5/5], Loss: 0.2610, Accuracy: 0.9068\n",
            "44 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9789, Accuracy: 0.5000\n",
            "Epoch [2/5], Loss: 0.4754, Accuracy: 0.8220\n",
            "Epoch [3/5], Loss: 0.3275, Accuracy: 0.9153\n",
            "Epoch [4/5], Loss: 0.2776, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.2482, Accuracy: 0.9322\n",
            "45 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0832, Accuracy: 0.5254\n",
            "Epoch [2/5], Loss: 0.8808, Accuracy: 0.5424\n",
            "Epoch [3/5], Loss: 0.8250, Accuracy: 0.5339\n",
            "Epoch [4/5], Loss: 0.5800, Accuracy: 0.8051\n",
            "Epoch [5/5], Loss: 0.3726, Accuracy: 0.8644\n",
            "46 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1012, Accuracy: 0.4915\n",
            "Epoch [2/5], Loss: 0.5981, Accuracy: 0.7797\n",
            "Epoch [3/5], Loss: 0.3291, Accuracy: 0.9153\n",
            "Epoch [4/5], Loss: 0.2155, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.1938, Accuracy: 0.9322\n",
            "47 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0704, Accuracy: 0.4831\n",
            "Epoch [2/5], Loss: 0.6870, Accuracy: 0.6949\n",
            "Epoch [3/5], Loss: 0.4172, Accuracy: 0.8559\n",
            "Epoch [4/5], Loss: 0.2778, Accuracy: 0.9153\n",
            "Epoch [5/5], Loss: 0.2900, Accuracy: 0.8983\n",
            "48 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0307, Accuracy: 0.5085\n",
            "Epoch [2/5], Loss: 0.5899, Accuracy: 0.7966\n",
            "Epoch [3/5], Loss: 0.3382, Accuracy: 0.8814\n",
            "Epoch [4/5], Loss: 0.2092, Accuracy: 0.9407\n",
            "Epoch [5/5], Loss: 0.1248, Accuracy: 0.9746\n",
            "49 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0548, Accuracy: 0.5000\n",
            "Epoch [2/5], Loss: 0.6721, Accuracy: 0.7373\n",
            "Epoch [3/5], Loss: 0.3340, Accuracy: 0.8983\n",
            "Epoch [4/5], Loss: 0.2019, Accuracy: 0.9322\n",
            "Epoch [5/5], Loss: 0.1666, Accuracy: 0.9407\n",
            "50 Run Complete!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define Transformer model\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, num_layers=1, num_heads=1, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(1, 0, 2)  # Shape: (seq_len, batch_size, embedding_dim)\n",
        "        output = self.transformer_encoder(x)\n",
        "        output = output.mean(dim=0)  # Average over sequence length\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['Label'] = label_encoder.fit_transform(train_df['Sentiment'])\n",
        "\n",
        "# Convert sentences to numerical representation\n",
        "vocab = set(\" \".join(train_df['Sentence']).split())\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "def sentence_to_indices(sentence):\n",
        "    indices = [word_to_index[word] for word in sentence.split()]\n",
        "    return indices\n",
        "\n",
        "train_data_indices = [sentence_to_indices(sentence) for sentence in train_df['Sentence']]\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_seq_length = max(len(indices) for indices in train_data_indices)\n",
        "train_data_padded = [indices + [0] * (max_seq_length - len(indices)) for indices in train_data_indices]\n",
        "\n",
        "# Convert data and labels to PyTorch tensors\n",
        "train_data_tensor = torch.tensor(train_data_padded, dtype=torch.long)\n",
        "train_labels_tensor = torch.tensor(train_df['Label'].values, dtype=torch.long)\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = len(vocab)  # Vocabulary size\n",
        "hidden_dim = 128\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "num_layers = 2\n",
        "num_heads = 4\n",
        "dropout = 0.1\n",
        "\n",
        "for i in range(n):\n",
        "    # Instantiate Transformer model\n",
        "    model = TransformerModel(input_dim, hidden_dim, num_classes, num_layers, num_heads, dropout)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Prepare DataLoader\n",
        "    batch_size = 2\n",
        "    train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    accuracies_Transformer=[]\n",
        "    start_time = time.time()  # Start time for each run\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 5\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * len(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == targets).sum().item()\n",
        "            total_samples += len(inputs)\n",
        "\n",
        "        epoch_loss = total_loss / total_samples\n",
        "        epoch_accuracy = total_correct / total_samples\n",
        "        accuracies_Transformer.append(epoch_accuracy)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "    end_time = time.time()  # End time for each run\n",
        "    runtime = end_time - start_time\n",
        "    Transformer_runtimes.append(runtime)\n",
        "    Transformer_accuracies.append(np.mean(accuracies_Transformer))\n",
        "    print(f\"{i+1} Run Complete!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik8N2n3RqPMw"
      },
      "source": [
        "### HyperMixer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uYTRj-iadWM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60aa8d0-d78c-43dd-e031-374fdd6e999f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.0746, Accuracy: 0.3814\n",
            "Epoch [2/5], Loss: 0.9130, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 0.8342, Accuracy: 0.5593\n",
            "Epoch [4/5], Loss: 0.7724, Accuracy: 0.6610\n",
            "Epoch [5/5], Loss: 0.6740, Accuracy: 0.7542\n",
            "1 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0505, Accuracy: 0.5169\n",
            "Epoch [2/5], Loss: 0.9056, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 0.7828, Accuracy: 0.6271\n",
            "Epoch [4/5], Loss: 0.7014, Accuracy: 0.7712\n",
            "Epoch [5/5], Loss: 0.5787, Accuracy: 0.7966\n",
            "2 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9183, Accuracy: 0.5763\n",
            "Epoch [2/5], Loss: 0.8423, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 0.7940, Accuracy: 0.6186\n",
            "Epoch [4/5], Loss: 0.7246, Accuracy: 0.6610\n",
            "Epoch [5/5], Loss: 0.5754, Accuracy: 0.8136\n",
            "3 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9752, Accuracy: 0.5508\n",
            "Epoch [2/5], Loss: 0.8486, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 0.7752, Accuracy: 0.6017\n",
            "Epoch [4/5], Loss: 0.6946, Accuracy: 0.7203\n",
            "Epoch [5/5], Loss: 0.5514, Accuracy: 0.8390\n",
            "4 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9262, Accuracy: 0.5763\n",
            "Epoch [2/5], Loss: 0.7922, Accuracy: 0.6441\n",
            "Epoch [3/5], Loss: 0.6868, Accuracy: 0.7034\n",
            "Epoch [4/5], Loss: 0.5521, Accuracy: 0.8390\n",
            "Epoch [5/5], Loss: 0.4180, Accuracy: 0.8559\n",
            "5 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0537, Accuracy: 0.4492\n",
            "Epoch [2/5], Loss: 0.8676, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 0.7848, Accuracy: 0.6525\n",
            "Epoch [4/5], Loss: 0.7158, Accuracy: 0.7119\n",
            "Epoch [5/5], Loss: 0.6082, Accuracy: 0.7966\n",
            "6 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0800, Accuracy: 0.3983\n",
            "Epoch [2/5], Loss: 0.8522, Accuracy: 0.5847\n",
            "Epoch [3/5], Loss: 0.7564, Accuracy: 0.6102\n",
            "Epoch [4/5], Loss: 0.6942, Accuracy: 0.6949\n",
            "Epoch [5/5], Loss: 0.5669, Accuracy: 0.7881\n",
            "7 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0445, Accuracy: 0.4068\n",
            "Epoch [2/5], Loss: 0.8828, Accuracy: 0.5593\n",
            "Epoch [3/5], Loss: 0.8215, Accuracy: 0.5254\n",
            "Epoch [4/5], Loss: 0.7582, Accuracy: 0.5847\n",
            "Epoch [5/5], Loss: 0.6529, Accuracy: 0.7373\n",
            "8 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0593, Accuracy: 0.3898\n",
            "Epoch [2/5], Loss: 0.8420, Accuracy: 0.6525\n",
            "Epoch [3/5], Loss: 0.7571, Accuracy: 0.6017\n",
            "Epoch [4/5], Loss: 0.6790, Accuracy: 0.7458\n",
            "Epoch [5/5], Loss: 0.5459, Accuracy: 0.7966\n",
            "9 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9100, Accuracy: 0.5847\n",
            "Epoch [2/5], Loss: 0.7022, Accuracy: 0.6695\n",
            "Epoch [3/5], Loss: 0.5230, Accuracy: 0.8220\n",
            "Epoch [4/5], Loss: 0.3498, Accuracy: 0.9068\n",
            "Epoch [5/5], Loss: 0.2392, Accuracy: 0.9237\n",
            "10 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9379, Accuracy: 0.5763\n",
            "Epoch [2/5], Loss: 0.8042, Accuracy: 0.5847\n",
            "Epoch [3/5], Loss: 0.7501, Accuracy: 0.6525\n",
            "Epoch [4/5], Loss: 0.6443, Accuracy: 0.7373\n",
            "Epoch [5/5], Loss: 0.4882, Accuracy: 0.8220\n",
            "11 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9180, Accuracy: 0.5593\n",
            "Epoch [2/5], Loss: 0.8071, Accuracy: 0.5847\n",
            "Epoch [3/5], Loss: 0.7445, Accuracy: 0.6186\n",
            "Epoch [4/5], Loss: 0.6724, Accuracy: 0.6695\n",
            "Epoch [5/5], Loss: 0.5364, Accuracy: 0.7881\n",
            "12 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9750, Accuracy: 0.4153\n",
            "Epoch [2/5], Loss: 0.8289, Accuracy: 0.5508\n",
            "Epoch [3/5], Loss: 0.7832, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 0.7060, Accuracy: 0.6864\n",
            "Epoch [5/5], Loss: 0.5723, Accuracy: 0.7712\n",
            "13 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0635, Accuracy: 0.3644\n",
            "Epoch [2/5], Loss: 0.8757, Accuracy: 0.5932\n",
            "Epoch [3/5], Loss: 0.7920, Accuracy: 0.6102\n",
            "Epoch [4/5], Loss: 0.7257, Accuracy: 0.6610\n",
            "Epoch [5/5], Loss: 0.6289, Accuracy: 0.7627\n",
            "14 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9309, Accuracy: 0.5678\n",
            "Epoch [2/5], Loss: 0.8380, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 0.7761, Accuracy: 0.6017\n",
            "Epoch [4/5], Loss: 0.6963, Accuracy: 0.6780\n",
            "Epoch [5/5], Loss: 0.5346, Accuracy: 0.8475\n",
            "15 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0824, Accuracy: 0.4068\n",
            "Epoch [2/5], Loss: 0.8501, Accuracy: 0.5424\n",
            "Epoch [3/5], Loss: 0.7854, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 0.7102, Accuracy: 0.6949\n",
            "Epoch [5/5], Loss: 0.5892, Accuracy: 0.8475\n",
            "16 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9782, Accuracy: 0.5593\n",
            "Epoch [2/5], Loss: 0.8529, Accuracy: 0.5508\n",
            "Epoch [3/5], Loss: 0.8185, Accuracy: 0.5763\n",
            "Epoch [4/5], Loss: 0.7704, Accuracy: 0.6017\n",
            "Epoch [5/5], Loss: 0.7032, Accuracy: 0.7203\n",
            "17 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.2431, Accuracy: 0.3559\n",
            "Epoch [2/5], Loss: 0.9123, Accuracy: 0.5508\n",
            "Epoch [3/5], Loss: 0.7804, Accuracy: 0.6186\n",
            "Epoch [4/5], Loss: 0.7011, Accuracy: 0.7119\n",
            "Epoch [5/5], Loss: 0.6008, Accuracy: 0.8051\n",
            "18 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9737, Accuracy: 0.5000\n",
            "Epoch [2/5], Loss: 0.8331, Accuracy: 0.5932\n",
            "Epoch [3/5], Loss: 0.7671, Accuracy: 0.6271\n",
            "Epoch [4/5], Loss: 0.6798, Accuracy: 0.7034\n",
            "Epoch [5/5], Loss: 0.6018, Accuracy: 0.7627\n",
            "19 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0420, Accuracy: 0.4322\n",
            "Epoch [2/5], Loss: 0.8615, Accuracy: 0.5424\n",
            "Epoch [3/5], Loss: 0.7995, Accuracy: 0.6102\n",
            "Epoch [4/5], Loss: 0.7461, Accuracy: 0.6525\n",
            "Epoch [5/5], Loss: 0.6630, Accuracy: 0.7288\n",
            "20 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9459, Accuracy: 0.4831\n",
            "Epoch [2/5], Loss: 0.8450, Accuracy: 0.6271\n",
            "Epoch [3/5], Loss: 0.7903, Accuracy: 0.6441\n",
            "Epoch [4/5], Loss: 0.7297, Accuracy: 0.6441\n",
            "Epoch [5/5], Loss: 0.6152, Accuracy: 0.8136\n",
            "21 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9888, Accuracy: 0.5085\n",
            "Epoch [2/5], Loss: 0.8467, Accuracy: 0.6441\n",
            "Epoch [3/5], Loss: 0.7966, Accuracy: 0.6271\n",
            "Epoch [4/5], Loss: 0.7573, Accuracy: 0.6780\n",
            "Epoch [5/5], Loss: 0.6826, Accuracy: 0.7627\n",
            "22 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0254, Accuracy: 0.4237\n",
            "Epoch [2/5], Loss: 0.8373, Accuracy: 0.5593\n",
            "Epoch [3/5], Loss: 0.7549, Accuracy: 0.6017\n",
            "Epoch [4/5], Loss: 0.6827, Accuracy: 0.7034\n",
            "Epoch [5/5], Loss: 0.5458, Accuracy: 0.7712\n",
            "23 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9760, Accuracy: 0.4068\n",
            "Epoch [2/5], Loss: 0.8300, Accuracy: 0.5424\n",
            "Epoch [3/5], Loss: 0.7737, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 0.7024, Accuracy: 0.6525\n",
            "Epoch [5/5], Loss: 0.5534, Accuracy: 0.7881\n",
            "24 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0098, Accuracy: 0.5254\n",
            "Epoch [2/5], Loss: 0.8564, Accuracy: 0.5932\n",
            "Epoch [3/5], Loss: 0.7969, Accuracy: 0.5932\n",
            "Epoch [4/5], Loss: 0.7209, Accuracy: 0.7458\n",
            "Epoch [5/5], Loss: 0.6030, Accuracy: 0.7881\n",
            "25 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0487, Accuracy: 0.4492\n",
            "Epoch [2/5], Loss: 0.8588, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 0.7756, Accuracy: 0.6695\n",
            "Epoch [4/5], Loss: 0.6930, Accuracy: 0.6864\n",
            "Epoch [5/5], Loss: 0.5557, Accuracy: 0.8220\n",
            "26 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1217, Accuracy: 0.3898\n",
            "Epoch [2/5], Loss: 0.9230, Accuracy: 0.6186\n",
            "Epoch [3/5], Loss: 0.7807, Accuracy: 0.6864\n",
            "Epoch [4/5], Loss: 0.6563, Accuracy: 0.7203\n",
            "Epoch [5/5], Loss: 0.5271, Accuracy: 0.8136\n",
            "27 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0973, Accuracy: 0.2797\n",
            "Epoch [2/5], Loss: 0.8877, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 0.8312, Accuracy: 0.5932\n",
            "Epoch [4/5], Loss: 0.7883, Accuracy: 0.6695\n",
            "Epoch [5/5], Loss: 0.7413, Accuracy: 0.6949\n",
            "28 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0350, Accuracy: 0.5424\n",
            "Epoch [2/5], Loss: 0.8763, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 0.8002, Accuracy: 0.6102\n",
            "Epoch [4/5], Loss: 0.7331, Accuracy: 0.6525\n",
            "Epoch [5/5], Loss: 0.6441, Accuracy: 0.7203\n",
            "29 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9752, Accuracy: 0.5424\n",
            "Epoch [2/5], Loss: 0.8495, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 0.8086, Accuracy: 0.5763\n",
            "Epoch [4/5], Loss: 0.7478, Accuracy: 0.6610\n",
            "Epoch [5/5], Loss: 0.6562, Accuracy: 0.7373\n",
            "30 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0271, Accuracy: 0.4322\n",
            "Epoch [2/5], Loss: 0.8676, Accuracy: 0.4831\n",
            "Epoch [3/5], Loss: 0.7952, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 0.7328, Accuracy: 0.6695\n",
            "Epoch [5/5], Loss: 0.6367, Accuracy: 0.7034\n",
            "31 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9505, Accuracy: 0.4661\n",
            "Epoch [2/5], Loss: 0.8381, Accuracy: 0.5593\n",
            "Epoch [3/5], Loss: 0.7790, Accuracy: 0.6695\n",
            "Epoch [4/5], Loss: 0.7141, Accuracy: 0.6525\n",
            "Epoch [5/5], Loss: 0.6104, Accuracy: 0.7627\n",
            "32 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0818, Accuracy: 0.4237\n",
            "Epoch [2/5], Loss: 0.9353, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 0.8307, Accuracy: 0.5932\n",
            "Epoch [4/5], Loss: 0.7966, Accuracy: 0.6271\n",
            "Epoch [5/5], Loss: 0.7067, Accuracy: 0.6949\n",
            "33 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0001, Accuracy: 0.5339\n",
            "Epoch [2/5], Loss: 0.7965, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 0.7017, Accuracy: 0.6186\n",
            "Epoch [4/5], Loss: 0.5996, Accuracy: 0.7712\n",
            "Epoch [5/5], Loss: 0.4751, Accuracy: 0.8305\n",
            "34 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9952, Accuracy: 0.5508\n",
            "Epoch [2/5], Loss: 0.8150, Accuracy: 0.6186\n",
            "Epoch [3/5], Loss: 0.7236, Accuracy: 0.6780\n",
            "Epoch [4/5], Loss: 0.6143, Accuracy: 0.7712\n",
            "Epoch [5/5], Loss: 0.4740, Accuracy: 0.8390\n",
            "35 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9187, Accuracy: 0.5339\n",
            "Epoch [2/5], Loss: 0.7980, Accuracy: 0.5932\n",
            "Epoch [3/5], Loss: 0.7365, Accuracy: 0.6864\n",
            "Epoch [4/5], Loss: 0.6138, Accuracy: 0.7881\n",
            "Epoch [5/5], Loss: 0.4687, Accuracy: 0.8305\n",
            "36 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9221, Accuracy: 0.5508\n",
            "Epoch [2/5], Loss: 0.8254, Accuracy: 0.5508\n",
            "Epoch [3/5], Loss: 0.7530, Accuracy: 0.6525\n",
            "Epoch [4/5], Loss: 0.6418, Accuracy: 0.7373\n",
            "Epoch [5/5], Loss: 0.4889, Accuracy: 0.8305\n",
            "37 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9557, Accuracy: 0.5169\n",
            "Epoch [2/5], Loss: 0.8517, Accuracy: 0.5932\n",
            "Epoch [3/5], Loss: 0.8225, Accuracy: 0.5763\n",
            "Epoch [4/5], Loss: 0.7877, Accuracy: 0.6780\n",
            "Epoch [5/5], Loss: 0.7304, Accuracy: 0.7542\n",
            "38 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0004, Accuracy: 0.5085\n",
            "Epoch [2/5], Loss: 0.8649, Accuracy: 0.5508\n",
            "Epoch [3/5], Loss: 0.8031, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 0.7467, Accuracy: 0.6356\n",
            "Epoch [5/5], Loss: 0.6512, Accuracy: 0.7119\n",
            "39 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9405, Accuracy: 0.5254\n",
            "Epoch [2/5], Loss: 0.8320, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 0.7750, Accuracy: 0.6017\n",
            "Epoch [4/5], Loss: 0.7047, Accuracy: 0.7203\n",
            "Epoch [5/5], Loss: 0.5870, Accuracy: 0.8051\n",
            "40 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9138, Accuracy: 0.5847\n",
            "Epoch [2/5], Loss: 0.7865, Accuracy: 0.6525\n",
            "Epoch [3/5], Loss: 0.6981, Accuracy: 0.7034\n",
            "Epoch [4/5], Loss: 0.5508, Accuracy: 0.7966\n",
            "Epoch [5/5], Loss: 0.4121, Accuracy: 0.8644\n",
            "41 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0171, Accuracy: 0.4237\n",
            "Epoch [2/5], Loss: 0.8537, Accuracy: 0.5508\n",
            "Epoch [3/5], Loss: 0.7737, Accuracy: 0.6271\n",
            "Epoch [4/5], Loss: 0.7023, Accuracy: 0.7119\n",
            "Epoch [5/5], Loss: 0.5808, Accuracy: 0.7797\n",
            "42 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9878, Accuracy: 0.3814\n",
            "Epoch [2/5], Loss: 0.8684, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 0.8378, Accuracy: 0.5678\n",
            "Epoch [4/5], Loss: 0.8132, Accuracy: 0.5678\n",
            "Epoch [5/5], Loss: 0.7731, Accuracy: 0.6102\n",
            "43 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.1858, Accuracy: 0.3136\n",
            "Epoch [2/5], Loss: 0.9234, Accuracy: 0.6356\n",
            "Epoch [3/5], Loss: 0.7619, Accuracy: 0.6949\n",
            "Epoch [4/5], Loss: 0.6334, Accuracy: 0.7797\n",
            "Epoch [5/5], Loss: 0.4776, Accuracy: 0.8898\n",
            "44 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9957, Accuracy: 0.4576\n",
            "Epoch [2/5], Loss: 0.8654, Accuracy: 0.5763\n",
            "Epoch [3/5], Loss: 0.8253, Accuracy: 0.5763\n",
            "Epoch [4/5], Loss: 0.7787, Accuracy: 0.6017\n",
            "Epoch [5/5], Loss: 0.6896, Accuracy: 0.7373\n",
            "45 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0820, Accuracy: 0.3898\n",
            "Epoch [2/5], Loss: 0.9083, Accuracy: 0.5678\n",
            "Epoch [3/5], Loss: 0.8332, Accuracy: 0.5932\n",
            "Epoch [4/5], Loss: 0.7953, Accuracy: 0.6271\n",
            "Epoch [5/5], Loss: 0.7191, Accuracy: 0.6949\n",
            "46 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0387, Accuracy: 0.3729\n",
            "Epoch [2/5], Loss: 0.8867, Accuracy: 0.4746\n",
            "Epoch [3/5], Loss: 0.8230, Accuracy: 0.6102\n",
            "Epoch [4/5], Loss: 0.7707, Accuracy: 0.5847\n",
            "Epoch [5/5], Loss: 0.6746, Accuracy: 0.7373\n",
            "47 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9954, Accuracy: 0.5254\n",
            "Epoch [2/5], Loss: 0.8410, Accuracy: 0.5847\n",
            "Epoch [3/5], Loss: 0.8058, Accuracy: 0.5932\n",
            "Epoch [4/5], Loss: 0.7850, Accuracy: 0.6441\n",
            "Epoch [5/5], Loss: 0.7379, Accuracy: 0.6610\n",
            "48 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 0.9341, Accuracy: 0.6017\n",
            "Epoch [2/5], Loss: 0.7924, Accuracy: 0.6271\n",
            "Epoch [3/5], Loss: 0.6881, Accuracy: 0.7288\n",
            "Epoch [4/5], Loss: 0.5826, Accuracy: 0.8136\n",
            "Epoch [5/5], Loss: 0.4769, Accuracy: 0.8559\n",
            "49 Run Complete!\n",
            "\n",
            "Epoch [1/5], Loss: 1.0783, Accuracy: 0.3644\n",
            "Epoch [2/5], Loss: 0.8683, Accuracy: 0.6017\n",
            "Epoch [3/5], Loss: 0.7782, Accuracy: 0.6525\n",
            "Epoch [4/5], Loss: 0.7019, Accuracy: 0.6780\n",
            "Epoch [5/5], Loss: 0.5745, Accuracy: 0.8390\n",
            "50 Run Complete!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define HyperMixer model\n",
        "class HyperMixerModel(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim: int,\n",
        "            hidden_dim: int,\n",
        "            num_classes: int,\n",
        "            norm_layer: type = nn.LayerNorm,\n",
        "            act_layer: type = nn.GELU,\n",
        "            drop: float = 0.\n",
        "    ) -> None:\n",
        "        super(HyperMixerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.mixer_block = HyperMixerBlock(hidden_dim, norm_layer=norm_layer, act_layer=act_layer, drop=drop)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.mixer_block(x)\n",
        "        x = torch.mean(x, dim=1)  # Average over tokens\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define HyperMixerBlock\n",
        "class HyperMixerBlock(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            hidden_dim: int,\n",
        "            norm_layer: type = nn.LayerNorm,\n",
        "            act_layer: type = nn.GELU,\n",
        "            drop: float = 0.\n",
        "    ) -> None:\n",
        "        super(HyperMixerBlock, self).__init__()\n",
        "        self.norm = norm_layer(hidden_dim)\n",
        "        self.mlp_tokens = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            act_layer(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Dropout(drop)\n",
        "        )\n",
        "        self.mlp_channels = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            act_layer(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Dropout(drop)\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            x: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        x = self.norm(x)\n",
        "        x = x + self.mlp_tokens(x)\n",
        "        x = x + self.mlp_channels(x.transpose(1, 2)).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['Label'] = label_encoder.fit_transform(train_df['Sentiment'])\n",
        "\n",
        "# Convert sentences to numerical representation\n",
        "vocab = set(\" \".join(train_df['Sentence']).split())\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "def sentence_to_indices(sentence):\n",
        "    indices = [word_to_index[word] for word in sentence.split()]\n",
        "    return indices\n",
        "\n",
        "train_data_indices = [sentence_to_indices(sentence) for sentence in train_df['Sentence']]\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_seq_length = max(len(indices) for indices in train_data_indices)\n",
        "train_data_padded = [indices + [0] * (max_seq_length - len(indices)) for indices in train_data_indices]\n",
        "\n",
        "# Convert data and labels to PyTorch tensors\n",
        "train_data_tensor = torch.tensor(train_data_padded, dtype=torch.long)\n",
        "train_labels_tensor = torch.tensor(train_df['Label'].values, dtype=torch.long)\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = len(vocab)  # Vocabulary size\n",
        "hidden_dim = 13\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "\n",
        "for i in range(n):\n",
        "    # Instantiate HyperMixer model\n",
        "    model = HyperMixerModel(input_dim, hidden_dim, num_classes)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Prepare DataLoader\n",
        "    batch_size = 2  # Adjusted for small dataset\n",
        "    train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    accuracies_HyperMixer=[]\n",
        "    start_time = time.time()  # Start time for each run\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 5\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * len(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == targets).sum().item()\n",
        "            total_samples += len(inputs)\n",
        "\n",
        "        epoch_loss = total_loss / total_samples\n",
        "        epoch_accuracy = total_correct / total_samples\n",
        "        accuracies_HyperMixer.append(epoch_accuracy)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "    end_time = time.time()  # End time for each run\n",
        "    runtime = end_time - start_time\n",
        "    HyperMixer_runtimes.append(runtime)\n",
        "    HyperMixer_accuracies.append(np.mean(accuracies_HyperMixer))\n",
        "    print(f\"{i+1} Run Complete!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "PZTohyE7xiJi",
        "outputId": "3129c9d0-e209-4c44-fe88-4b23f485f3a4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"34345ee6-4f03-4c52-b754-698ebe4e4d05\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"34345ee6-4f03-4c52-b754-698ebe4e4d05\")) {                    Plotly.newPlot(                        \"34345ee6-4f03-4c52-b754-698ebe4e4d05\",                        [{\"line\":{\"dash\":\"solid\",\"width\":5},\"mode\":\"lines+markers\",\"name\":\"HyperMixer\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50],\"y\":[0.5864406779661018,0.6559322033898305,0.6491525423728814,0.6576271186440679,0.723728813559322,0.6372881355932203,0.6152542372881357,0.5627118644067798,0.6372881355932203,0.7813559322033898,0.6745762711864407,0.6440677966101696,0.5983050847457627,0.5983050847457626,0.652542372881356,0.611864406779661,0.6016949152542372,0.6084745762711864,0.6372881355932203,0.5932203389830508,0.6423728813559322,0.6440677966101696,0.611864406779661,0.5915254237288136,0.6491525423728814,0.6389830508474577,0.6457627118644067,0.5610169491525424,0.6203389830508474,0.616949152542373,0.5711864406779661,0.6220338983050848,0.5813559322033898,0.6661016949152543,0.6915254237288135,0.6864406779661018,0.6644067796610169,0.623728813559322,0.5949152542372881,0.6440677966101696,0.7203389830508475,0.6186440677966102,0.5406779661016949,0.6627118644067796,0.5898305084745763,0.5745762711864406,0.5559322033898306,0.6016949152542372,0.7254237288135592,0.6271186440677965],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgb(250, 100, 147)\",\"dash\":\"solid\",\"width\":2},\"mode\":\"lines+markers\",\"name\":\"Transformers\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50],\"y\":[0.7915254237288135,0.735593220338983,0.7661016949152541,0.8152542372881356,0.7610169491525424,0.8389830508474576,0.7542372881355932,0.723728813559322,0.8338983050847457,0.8033898305084746,0.8050847457627117,0.8491525423728813,0.8355932203389831,0.7254237288135593,0.7949152542372881,0.6542372881355932,0.5915254237288136,0.8033898305084746,0.7186440677966102,0.7762711864406779,0.8254237288135593,0.7423728813559322,0.864406779661017,0.8491525423728815,0.7067796610169491,0.8711864406779661,0.8,0.8237288135593221,0.7457627118644068,0.7237288135593221,0.8135593220338982,0.7525423728813558,0.6084745762711865,0.6254237288135593,0.7762711864406778,0.7779661016949153,0.6694915254237289,0.8152542372881356,0.7779661016949153,0.8033898305084746,0.7932203389830509,0.6915254237288135,0.7915254237288135,0.6966101694915254,0.8203389830508476,0.6542372881355932,0.8101694915254238,0.7694915254237289,0.8203389830508474,0.8016949152542372],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"MLPMixer\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50],\"y\":[0.3067796610169492,0.31864406779661014,0.5677966101694916,0.5593220338983051,0.4084745762711865,0.19661016949152543,0.3813559322033898,0.6220338983050848,0.5508474576271187,0.5677966101694916,0.4728813559322034,0.5576271186440678,0.31864406779661014,0.6898305084745763,0.7101694915254237,0.23389830508474577,0.19491525423728814,0.6830508474576271,0.5559322033898305,0.7,0.5677966101694916,0.359322033898305,0.5677966101694916,0.5661016949152542,0.42372881355932196,0.6254237288135593,0.5677966101694916,0.47966101694915253,0.5525423728813559,0.5677966101694916,0.5728813559322035,0.5203389830508474,0.5305084745762711,0.4406779661016949,0.39322033898305087,0.5389830508474576,0.6,0.5677966101694916,0.7152542372881356,0.6135593220338984,0.4169491525423729,0.3813559322033898,0.5372881355932203,0.476271186440678,0.759322033898305,0.43728813559322044,0.4,0.5932203389830508,0.7203389830508475,0.5677966101694916],\"type\":\"scatter\"}],                        {\"hovermode\":\"closest\",\"legend\":{\"x\":0,\"y\":1.0},\"plot_bgcolor\":\"rgba(0,0,0,0)\",\"title\":{\"text\":\"Model Accuracies\"},\"xaxis\":{\"title\":{\"text\":\"Number of Runs\"}},\"yaxis\":{\"title\":{\"text\":\"Accuracy\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('34345ee6-4f03-4c52-b754-698ebe4e4d05');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.graph_objs as go\n",
        "\n",
        "number_of_runs = list(range(1, n+1))\n",
        "\n",
        "# Assuming you have defined HyperMixer_accuracies, Transformer_accuracies, and MLP_mixer_accuracies somewhere\n",
        "\n",
        "# Plotting\n",
        "trace1 = go.Scatter(x=number_of_runs, y=HyperMixer_accuracies, mode='lines+markers', name='HyperMixer', line=dict(width=5, dash='solid'))\n",
        "trace2 = go.Scatter(x=number_of_runs, y=Transformer_accuracies, mode='lines+markers', name='Transformers', line=dict(color='rgb(250, 100, 147)', width=2, dash='solid'))\n",
        "trace3 = go.Scatter(x=number_of_runs, y=MLP_mixer_accuracies, mode='lines+markers', name='MLPMixer')\n",
        "\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Model Accuracies',\n",
        "    xaxis=dict(title='Number of Runs'),\n",
        "    yaxis=dict(title='Accuracy'),\n",
        "    legend=dict(x=0, y=1.0),\n",
        "    hovermode='closest',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n",
        "\n",
        "# To display the plot in Jupyter Notebook or Jupyter Lab\n",
        "# If you're using a different environment, you may need to use the appropriate display function.\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9jg2pcWgfOTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6049b2da-9ee3-4b1d-f369-cbbd6afacf99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5131525423728814, 0.768, 0.6302372881355932)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Average Accuracies\n",
        "\n",
        "np.mean(MLP_mixer_accuracies), np.mean(Transformer_accuracies),np.mean(HyperMixer_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4N1GnL6PWggu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "ccc7167f-bfb0-491a-fc22-d3aec1e86e2d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"d77a6e73-cc8a-4b49-8c6b-5fd17c3163b3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d77a6e73-cc8a-4b49-8c6b-5fd17c3163b3\")) {                    Plotly.newPlot(                        \"d77a6e73-cc8a-4b49-8c6b-5fd17c3163b3\",                        [{\"line\":{\"dash\":\"solid\",\"width\":5},\"mode\":\"lines+markers\",\"name\":\"HyperMixer\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50],\"y\":[0.8272809982299805,0.7807948589324951,0.7885065078735352,0.7503025531768799,0.7748584747314453,0.778087854385376,0.7815792560577393,0.7837164402008057,0.8170466423034668,0.7759613990783691,0.796536922454834,0.8774058818817139,1.0898504257202148,1.1493918895721436,0.7646007537841797,0.7365195751190186,0.7898678779602051,0.7574360370635986,0.7743573188781738,0.8028767108917236,0.7821764945983887,0.8027846813201904,0.8134729862213135,0.7661592960357666,0.8277063369750977,0.7864933013916016,0.9120981693267822,1.074007511138916,1.0438408851623535,0.7526755332946777,0.771883487701416,0.745520830154419,0.7954704761505127,0.7555551528930664,0.7784266471862793,0.754802942276001,0.772702693939209,0.7636959552764893,0.7939043045043945,0.7715160846710205,0.7948970794677734,0.9271392822265625,1.0886831283569336,1.0794870853424072,0.797520637512207,0.7828214168548584,0.7257800102233887,0.779895544052124,0.7974526882171631,0.7750735282897949],\"type\":\"scatter\"},{\"line\":{\"color\":\"rgb(250, 100, 147)\",\"dash\":\"solid\",\"width\":2},\"mode\":\"lines+markers\",\"name\":\"Transformers\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50],\"y\":[5.924322605133057,4.50286078453064,4.916731357574463,5.123968839645386,4.591968297958374,5.280106067657471,4.521084547042847,4.747796535491943,5.046744108200073,4.594539403915405,5.191392421722412,4.487797021865845,4.438545227050781,5.259315013885498,4.521894216537476,4.901477813720703,4.781081676483154,4.449287176132202,5.159116506576538,4.5597803592681885,4.6243462562561035,5.130491018295288,4.606248617172241,5.230774402618408,4.520285606384277,4.6277008056640625,5.140752077102661,4.527944326400757,4.95627498626709,4.763626337051392,4.5466742515563965,5.218296051025391,4.666641712188721,4.596602201461792,5.104595899581909,4.485791444778442,5.259007930755615,4.549978971481323,4.561811447143555,5.280742883682251,4.45289158821106,5.008646011352539,4.6184632778167725,4.446275234222412,5.371101140975952,4.5206403732299805,4.753660202026367,4.991395950317383,4.544450759887695,5.184413433074951],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"MLPMixer\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50],\"y\":[0.1703963279724121,0.014869928359985352,0.014883041381835938,0.014789104461669922,0.014929533004760742,0.014899969100952148,0.014780759811401367,0.01772594451904297,0.014812707901000977,0.014455556869506836,0.014772415161132812,0.014699697494506836,0.02223658561706543,0.015291929244995117,0.01495218276977539,0.015537738800048828,0.015504121780395508,0.02051258087158203,0.014933109283447266,0.015613555908203125,0.014929056167602539,0.014645814895629883,0.01450204849243164,0.019016027450561523,0.014833688735961914,0.015012025833129883,0.016057491302490234,0.014855384826660156,0.014814615249633789,0.0147247314453125,0.017554759979248047,0.018279314041137695,0.014693498611450195,0.017019987106323242,0.014570236206054688,0.01856541633605957,0.019260406494140625,0.018967151641845703,0.015125274658203125,0.014035701751708984,0.01503896713256836,0.014829158782958984,0.015163421630859375,0.01469278335571289,0.014959573745727539,0.014994144439697266,0.014936208724975586,0.023171424865722656,0.014957666397094727,0.014723777770996094],\"type\":\"scatter\"}],                        {\"hovermode\":\"closest\",\"legend\":{\"x\":0,\"y\":1.0},\"plot_bgcolor\":\"rgba(0,0,0,0)\",\"title\":{\"text\":\"Model Runtimes\"},\"xaxis\":{\"title\":{\"text\":\"Number of Runs\"}},\"yaxis\":{\"title\":{\"text\":\"Runtime\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d77a6e73-cc8a-4b49-8c6b-5fd17c3163b3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.graph_objs as go\n",
        "\n",
        "number_of_runs = list(range(1, n+1))\n",
        "\n",
        "# Assuming you have defined MLP_mixer_runtimes, Transformer_runtimes, and HyperMixer_runtimes somewhere\n",
        "\n",
        "# Plotting\n",
        "trace1 = go.Scatter(x=number_of_runs, y=HyperMixer_runtimes, mode='lines+markers', name='HyperMixer', line=dict(width=5, dash='solid'))\n",
        "trace2 = go.Scatter(x=number_of_runs, y=Transformer_runtimes, mode='lines+markers', name='Transformers', line=dict(color='rgb(250, 100, 147)', width=2, dash='solid'))\n",
        "trace3 = go.Scatter(x=number_of_runs, y=MLP_mixer_runtimes, mode='lines+markers', name='MLPMixer')\n",
        "\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Model Runtimes',\n",
        "    xaxis=dict(title='Number of Runs'),\n",
        "    yaxis=dict(title='Runtime'),\n",
        "    legend=dict(x=0, y=1.0),\n",
        "    hovermode='closest',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SDb2kqt0Ws4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6ffd6d-921b-452f-9309-00ac1dca73ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.018990530967712402, 4.825806703567505, 0.8242124509811402)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Average Runtime\n",
        "\n",
        "np.mean(MLP_mixer_runtimes), np.mean(Transformer_runtimes),np.mean(HyperMixer_runtimes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}